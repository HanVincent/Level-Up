{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('../uncased_L-12_H-768_A-12')\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('../uncased_L-12_H-768_A-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    text = \"[CLS] \" + sent + \" [SEP]\"\n",
    "\n",
    "    # Tokenize\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    \n",
    "    # Convert token to vocabulary indices\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "    # Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "    segments_ids = [0]*len(indexed_tokens)\n",
    "\n",
    "    return tokenized_text, indexed_tokens, segments_ids\n",
    "\n",
    "\n",
    "def get_representation(indexed_tokens, segments_ids):\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    # If you have a GPU, put everything on cuda\n",
    "    tokens_tensor = tokens_tensor.to('cuda')\n",
    "    segments_tensors = segments_tensors.to('cuda')\n",
    "    model.to('cuda')\n",
    "    \n",
    "    # Predict hidden states features for each layer\n",
    "    with torch.no_grad():\n",
    "        encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "        return encoded_layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = torch.stack(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\"I try to finish the project.\"]\n",
    "\n",
    "sent = sents[0].lower().strip()\n",
    "tokenized_text, indexed_tokens, segments_ids = tokenize(sent)\n",
    "embeddings = get_representation(indexed_tokens, segments_ids)\n",
    "\n",
    "index = tokenized_text.index('try')\n",
    "target_emb = embeddings[0][index]\n",
    "\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "output = cos(target_emb.unsqueeze(0), vectors)\n",
    "    \n",
    "matches = output > 0.7\n",
    "if any(matches):\n",
    "    for i, is_match in enumerate(matches):\n",
    "        if is_match:\n",
    "            example_idx = indices[i]\n",
    "            print(examples[example_idx])\n",
    "            print(info_pairs[example_idx])\n",
    "            print(output[i:i+5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "from utils.config import level_table\n",
    "from itertools import product\n",
    "\n",
    "class EVP:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.vocab_level = {}\n",
    "\n",
    "        for line in open('./data/cambridge.dict.slim.txt', 'r', encoding='utf8'):\n",
    "            vocab, level, poss, gw, href = line.split('\\t')\n",
    "\n",
    "            if (vocab not in self.vocab_level or\n",
    "               level_table[level] < level_table[self.vocab_level[vocab]]):\n",
    "                self.vocab_level[vocab] = level\n",
    "\n",
    "    def lookup(self, vocab):\n",
    "        if vocab not in self.vocab_level:\n",
    "            return None\n",
    "\n",
    "        return self.vocab_level[vocab]\n",
    "\n",
    "    \n",
    "def duplicate_sent(sent):\n",
    "    sent = sent.replace('\\\\', '')\n",
    "    tokens = []\n",
    "    for token in sent.split():\n",
    "        tokens.append(token.split('/') if '/' in token else [token])\n",
    "\n",
    "    composes = product(*tokens)\n",
    "    sents = [' '.join(compose) for compose in composes]\n",
    "    \n",
    "    return sents\n",
    "\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "vocab_level = defaultdict(list)\n",
    "dictionary = json.load(open('data/cambridge.dict.json', 'r', encoding='utf8'))\n",
    "\n",
    "for vocab in dictionary:\n",
    "    for pos in dictionary[vocab]:\n",
    "        for each in dictionary[vocab][pos]:\n",
    "            indices, vectors = [], []\n",
    "\n",
    "            example = each['dic_examples'][0] if each['dic_examples'] else ''\n",
    "            example = duplicate_sent(example)[0].lower().strip()\n",
    "            tokenized_text, indexed_tokens, segments_ids = tokenize(example)\n",
    "\n",
    "            embeddings = get_representation(indexed_tokens, segments_ids)\n",
    "\n",
    "            index = tokenized_text.index(vocab)\n",
    "            word_emb = embeddings[0][index]\n",
    "            \n",
    "            vocab_level[vocab].append({\n",
    "                'level': each['level'],\n",
    "                'definition': each['definition'],\n",
    "                'emb': word_emb,\n",
    "                'example': example\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from utils.EVP import Evp\n",
    "from utils.config import level_table\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('/atom/word_vectors/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_vocab(vocab):\n",
    "    if Evp.vocab_exists(vocab):\n",
    "        level, poss = Evp.get_level(vocab), Evp.get_pos(vocab)\n",
    "        \n",
    "        if vocab in model:\n",
    "            sims = model.similar_by_word(vocab, topn=100)\n",
    "            recs = [{ 'vocab': sim, 'level': Evp.get_level(sim) } for sim, score in sims \n",
    "                    if Evp.vocab_exists(sim) and level_table[Evp.get_level(sim)] > level_table[level] and len(Evp.get_pos(sim) & poss) > 0]\n",
    "\n",
    "            return recs[:10]\n",
    "\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'vocab': 'consume', 'level': 'B2'}, {'vocab': 'chew', 'level': 'B2'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_vocab('eat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Evp.lookup_by_sense('set', 'he sets up the house.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
