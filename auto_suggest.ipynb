{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and Data analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from utils.config import tag2pos_table, level_table\n",
    "from utils.EGP import Egp\n",
    "from utils.EVP import Evp\n",
    "from utils.BNC import Bnc\n",
    "import kenlm\n",
    "\n",
    "model = kenlm.Model('/home/nlplab/jjc/gec/lm/coca.prune.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm(last_sent, ngram):\n",
    "    sentence = last_sent + ' ' + ngram\n",
    "    score = model.score(sentence, bos=True, eos=False) # / len(sentence.split())\n",
    "    return score\n",
    "\n",
    "\n",
    "def level_score(ngram):\n",
    "    levels = [Evp.get_level(token) for token in ngram.split()]\n",
    "    score = sum([level_table[level] if level else 0 for level in levels]) / len(levels)\n",
    "    return score\n",
    "\n",
    "\n",
    "def normalize_tag(tag):\n",
    "    return tag2pos_table[tag]+'.' if tag in tag2pos_table else tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_patterns(related_patterns, text_sent, headword, pos, top_k=1):\n",
    "    # not containing related ngram patterns\n",
    "    related_patterns = filter(lambda ptn: ptn[1] not in [12] and headword in Bnc.ngram_groups[ptn], related_patterns)\n",
    "\n",
    "    # group patterns by number\n",
    "    pattern_groups = defaultdict(list)\n",
    "    for pattern, no in related_patterns:\n",
    "        pattern_groups[no].append(pattern)\n",
    "        \n",
    "    # calc LM and get top k\n",
    "    targets = []\n",
    "    for no in pattern_groups:\n",
    "        candidates = [ng for pattern in pattern_groups[no] for ng in Bnc.ngram_groups[(pattern, no)][headword]]\n",
    "        candidates = filter(lambda ng: len(ng.split()) < 7, candidates)\n",
    "        candidates = filter(lambda ng: len(Bnc.sentences[ng]) > 1, candidates)\n",
    "        scores = [(ng, level_score(ng), lm(text_sent, ng)) for ng in candidates]\n",
    "        scores = sorted(scores, key=lambda x: x[2], reverse=True)[:10]\n",
    "\n",
    "        if len(scores) > 0:\n",
    "            ngram = max(scores, key=lambda x: x[1])[0]\n",
    "            targets.append({'no': no, 'level': Egp.get_level(no), 'pos': normalize_tag(pos), \n",
    "                            'lm': sum(score[2] for score in scores) / len(scores),\n",
    "                            'pattern': Egp.get_norm_pattern(no), 'ngram': ngram,\n",
    "                            'category': Egp.get_category(no), 'subcategory': Egp.get_subcategory(no),\n",
    "                            'statement': Egp.get_statement(no) } )\n",
    "    \n",
    "    # sort by lm\n",
    "    targets = sorted(targets, key=lambda t: t['lm'], reverse=True)\n",
    "    \n",
    "    return targets\n",
    "\n",
    "\n",
    "def suggest_sentences(ngram):\n",
    "    return Bnc.sentences[ngram][:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.grammar import iterate_all_patterns\n",
    "\n",
    "def auto_suggest(parse_sent, gets):\n",
    "    headword, pos = parse_sent[-1].text, parse_sent[-1].tag_\n",
    "    text_sent = parse_sent.text.rsplit(' ', maxsplit=1)[0] # to text\n",
    "    \n",
    "    # get max get\n",
    "    last_index = len(parse_sent) - 1\n",
    "    gets = [get for get in gets if last_index in get['indices']]\n",
    "    get = None\n",
    "    \n",
    "    related_patterns = Bnc.pattern_groups[pos].union(Bnc.pattern_groups[headword])\n",
    "    if len(gets) > 0:\n",
    "        get = max(gets, key=lambda get: level_table[get['level']])\n",
    "        get['pattern'] = Egp.get_norm_pattern(get['no'])\n",
    "        related_patterns = filter(lambda ptn: level_table[Egp.get_level(ptn[1])] > level_table[get['level']] and get['no'] != ptn[1], related_patterns)\n",
    "    \n",
    "    patterns = suggest_patterns(related_patterns, text_sent, headword, pos)\n",
    "\n",
    "    return get, { 'patterns': patterns, 'collocations': [] }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'no': 133,\n",
       "  'level': 'A2',\n",
       "  'indices': [0],\n",
       "  'ngram': 'Really',\n",
       "  'match': 'RB',\n",
       "  'category': 'ADVERBS',\n",
       "  'subcategory': 'position',\n",
       "  'statement': 'Can use an increasing range of adverbs in front position.',\n",
       "  'pattern': '<start> adv.'},\n",
       " {'patterns': [], 'collocations': []})"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.parser import nlp\n",
    "parse = nlp('Really')\n",
    "auto_suggest(parse, iterate_all_patterns(parse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def auto_suggest(headword, pos, last_sent):\n",
    "#     related_patterns = pattern_groups[headword] + pattern_groups[pos] # get headword matched POS and first word\n",
    "#     related_patterns = [related_pat for related_pat in related_patterns if headword in ngram_groups[related_pat]]\n",
    "\n",
    "#     # merge same number rule\n",
    "#     total = Counter()\n",
    "#     for pattern, no in related_patterns: \n",
    "#         for ngram in ngram_groups[(pattern, no)][headword]:\n",
    "#             total[no] += ngrams[(pattern, no)][ngram]\n",
    "#     top_k_keys = dict(total.most_common(3))\n",
    "\n",
    "#     # get top k patterns\n",
    "#     target_patterns = filter(lambda key: key[1] in top_k_keys, related_patterns)\n",
    "\n",
    "#     # normalize patterns\n",
    "#     target_norm_patterns = defaultdict(list)\n",
    "#     for pattern, no in target_patterns:\n",
    "#         target_norm_patterns[normalize_pattern(headword, pattern)].append((pattern, no))\n",
    "        \n",
    "#     # retrieve ngrams example\n",
    "#     total = 0\n",
    "#     target_ngrams = []\n",
    "#     for norm_pattern in target_norm_patterns: # (pattern, no)\n",
    "#         scores = [lm(last_sent, ng) for pattern, no in target_norm_patterns[norm_pattern] \n",
    "#                   for ng in ngram_groups[(pattern, no)][headword]] # get ngram in given patterns\n",
    "#         scores = sorted(scores, key=lambda x: x[1], reverse=True)[:3]\n",
    "\n",
    "#         t_ngrams = [ng[0] for ng in scores]\n",
    "#         avg = 1 / abs(sum([s[1] for s in scores]) / len(scores))\n",
    "#         total += avg        \n",
    "\n",
    "#         target_ngrams.append({\n",
    "#             'pattern': norm_pattern, 'pos': normalize_tag(pos),\n",
    "#             'no': no, 'level': Egp.get_level(no), \n",
    "#             # 'count': counts[(pattern, no)], \n",
    "#             'lm': avg,\n",
    "#             'category': Egp.get_category(no), 'subcategory': Egp.get_subcategory(no),\n",
    "#             'ngrams': t_ngrams, \n",
    "#             'sentence': sentences[t_ngrams[0]][0] })\n",
    "\n",
    "#     # get means and sorted\n",
    "#     for ng in target_ngrams: \n",
    "#         ng['lm'] = ng['lm'] / total\n",
    "        \n",
    "#     return target_ngrams\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
